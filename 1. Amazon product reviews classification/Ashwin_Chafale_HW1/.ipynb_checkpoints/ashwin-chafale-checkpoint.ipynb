{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CSCI-544 Homework Assignment No. 1\n",
    "### Name : Ashwin Chafale\n",
    "### USC ID : 1990624801"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sentiment Analysis on Amazon reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (from bs4) (4.11.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.3.1)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ashwin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/ashwin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ashwin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installation before running the notebook\n",
    "! pip install bs4\n",
    "! pip install contractions\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read Data\n",
    "1. [Amazon reviews dataset](https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz)\n",
    "2. Our goal is to train sentiment analysis classifiers that can predict the rating value for a given review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"amazon_reviews_us_Jewelry_v1_00.tsv\", sep='\\t', header=0, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>so beautiful even tho clearly not high end ......</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great product.. I got this set for my mother, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exactly as pictured and my daughter's friend l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Love it. Fits great. Super comfortable and nea...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Got this as a Mother's Day gift for my Mom and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         review_body star_rating\n",
       "0  so beautiful even tho clearly not high end ......           5\n",
       "1  Great product.. I got this set for my mother, ...           5\n",
       "2  Exactly as pictured and my daughter's friend l...           5\n",
       "3  Love it. Fits great. Super comfortable and nea...           5\n",
       "4  Got this as a Mother's Day gift for my Mom and...           5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['review_body','star_rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Removing `Null` and missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1766748, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    " ## We select 20000 reviews randomly from each rating class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['star_rating'] = df['star_rating'].astype(int)\n",
    "\n",
    "sample_size  = 20000\n",
    "five_star =  df.loc[ df['star_rating'] == 5].sample(sample_size)\n",
    "four_star =  df.loc[ df['star_rating'] == 4].sample(sample_size)\n",
    "three_star =  df.loc[ df['star_rating'] == 3].sample(sample_size)\n",
    "two_star =  df.loc[ df['star_rating'] == 2].sample(sample_size)\n",
    "one_star =  df.loc[ df['star_rating'] == 1].sample(sample_size)\n",
    "\n",
    "data = pd.concat([five_star, four_star, three_star, two_star, one_star], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of reviews before Data Cleaning step =  130.81458\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of reviews before Data Cleaning step = \", data['review_body'].str.len().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Converting all reviews to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert all reviews to lower case\n",
    "data[\"pre_process\"] = data['review_body'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Removing the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove HTML tags as well as URLs from reviews.\n",
    "data[\"pre_process\"] = data[\"pre_process\"].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "data[\"pre_process\"] = data[\"pre_process\"].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Perform \"Contractions\" on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# contractions\n",
    "import contractions\n",
    "data[\"pre_process\"] = data[\"pre_process\"].apply(lambda x:contractions.fix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Remove the non-alpha characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove the non-alpha characters\n",
    "data[\"pre_process\"] = data[\"pre_process\"].apply(lambda x: \" \".join([re.sub(\"[^A-Za-z]+\",\"\", x) for x in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Remove extra spaces among the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove extra spaces among the words\n",
    "data['pre_process'] = data['pre_process'].apply(lambda x: re.sub(' +', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of reviews after Data Cleaning step =  130.81458\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of reviews after Data Cleaning step = \", data['review_body'].str.len().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of reviews before Data Pre-processing step =  130.81458\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of reviews before Data Pre-processing step = \", data['review_body'].str.len().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Remove stop words\n",
    "\n",
    "Note: Just for the purpose of pre-processing I have shown the stop-words removal.\n",
    "However, the stop-word removed pre-processed data is not used to train the model.\n",
    "\n",
    "Reason for not performing stop-word removing step:\n",
    "*I have noticed that after stop-words are not removed it leads to increase in average precision of all the ML models by 10%.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_copy = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove stop words using a NLTK package\n",
    "from nltk.corpus import stopwords\n",
    "sw_nltk = stopwords.words('english')\n",
    "sw_nltk.remove(\"not\")\n",
    "sw_nltk.remove(\"don\")\n",
    "sw_nltk.remove(\"don't\")\n",
    "sw_nltk.remove(\"aren't\")\n",
    "sw_nltk.remove(\"couldn't\")\n",
    "sw_nltk.remove(\"couldn\")\n",
    "sw_nltk.remove(\"didn\")\n",
    "sw_nltk.remove(\"didn't\")\n",
    "sw_nltk.remove(\"doesn\")\n",
    "sw_nltk.remove(\"doesn't\")\n",
    "sw_nltk.remove(\"won\")\n",
    "sw_nltk.remove(\"won't\")\n",
    "data_copy['pre_process'] = data_copy['pre_process'].apply(lambda x: \" \".join([x for x in x.split() if x not in sw_nltk]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of reviews after Data Pre-processing step =  78.67438\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of reviews after Data Pre-processing step = \", data_copy['pre_process'].str.len().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Perform Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lemmatization using wordnet lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['pre_process'] = data['pre_process'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (80000,) (80000,) Test:  ((20000,), (20000,))\n"
     ]
    }
   ],
   "source": [
    "# Train - test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "five_star_X_train, five_star_X_test, five_star_Y_train, five_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 5][\"pre_process\"], \\\n",
    "                 data[data[\"star_rating\"] == 5][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "four_star_X_train, four_star_X_test, four_star_Y_train, four_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 4][\"pre_process\"], \\\n",
    "                 data[data[\"star_rating\"] == 4][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "three_star_X_train, three_star_X_test, three_star_Y_train, three_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 3][\"pre_process\"], \\\n",
    "                 data[data[\"star_rating\"] == 3][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "two_star_X_train, two_star_X_test, two_star_Y_train, two_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 2][\"pre_process\"], \\\n",
    "                 data[data[\"star_rating\"] == 2][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "one_star_X_train, one_star_X_test, one_star_Y_train, one_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 1][\"pre_process\"], \\\n",
    "                 data[data[\"star_rating\"] == 1][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "X_train = pd.concat([five_star_X_train, four_star_X_train, three_star_X_train, two_star_X_train, one_star_X_train])\n",
    "X_test = pd.concat([five_star_X_test, four_star_X_test, three_star_X_test, two_star_X_test, one_star_X_test])\n",
    "Y_train = pd.concat([five_star_Y_train, four_star_Y_train, three_star_Y_train, two_star_Y_train, one_star_Y_train])\n",
    "Y_test = pd.concat([five_star_Y_test, four_star_Y_test, three_star_Y_test, two_star_Y_test, one_star_Y_test])\n",
    "\n",
    "print(\"Train: \", X_train.shape, Y_train.shape, \"Test: \", (X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TF-IDF step\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf_vector =  TfidfVectorizer()\n",
    "tf_x_train = tf_idf_vector.fit_transform(X_train)\n",
    "tf_x_test = tf_idf_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.529361</td>\n",
       "      <td>0.302142</td>\n",
       "      <td>0.320768</td>\n",
       "      <td>0.383514</td>\n",
       "      <td>0.590234</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.425204</td>\n",
       "      <td>0.425204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.462000</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>0.221250</td>\n",
       "      <td>0.361750</td>\n",
       "      <td>0.556000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.414000</td>\n",
       "      <td>0.414000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.493392</td>\n",
       "      <td>0.367519</td>\n",
       "      <td>0.261873</td>\n",
       "      <td>0.372314</td>\n",
       "      <td>0.572606</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0.413541</td>\n",
       "      <td>0.413541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.414</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1            2            3            4            5  \\\n",
       "precision     0.529361     0.302142     0.320768     0.383514     0.590234   \n",
       "recall        0.462000     0.469000     0.221250     0.361750     0.556000   \n",
       "f1-score      0.493392     0.367519     0.261873     0.372314     0.572606   \n",
       "support    4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "\n",
       "           accuracy     macro avg  weighted avg  \n",
       "precision     0.414      0.425204      0.425204  \n",
       "recall        0.414      0.414000      0.414000  \n",
       "f1-score      0.414      0.413541      0.413541  \n",
       "support       0.414  20000.000000  20000.000000  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "perceptron = Perceptron(max_iter=1000, random_state=0)\n",
    "perceptron.fit(tf_x_train,Y_train)\n",
    "y_test_predicted = perceptron.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.563424</td>\n",
       "      <td>0.404890</td>\n",
       "      <td>0.424075</td>\n",
       "      <td>0.472624</td>\n",
       "      <td>0.639847</td>\n",
       "      <td>0.51355</td>\n",
       "      <td>0.500972</td>\n",
       "      <td>0.500972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.676250</td>\n",
       "      <td>0.339500</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>0.416500</td>\n",
       "      <td>0.751500</td>\n",
       "      <td>0.51355</td>\n",
       "      <td>0.513550</td>\n",
       "      <td>0.513550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.614703</td>\n",
       "      <td>0.369323</td>\n",
       "      <td>0.403044</td>\n",
       "      <td>0.442791</td>\n",
       "      <td>0.691193</td>\n",
       "      <td>0.51355</td>\n",
       "      <td>0.504211</td>\n",
       "      <td>0.504211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.51355</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1            2            3            4            5  \\\n",
       "precision     0.563424     0.404890     0.424075     0.472624     0.639847   \n",
       "recall        0.676250     0.339500     0.384000     0.416500     0.751500   \n",
       "f1-score      0.614703     0.369323     0.403044     0.442791     0.691193   \n",
       "support    4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "\n",
       "           accuracy     macro avg  weighted avg  \n",
       "precision   0.51355      0.500972      0.500972  \n",
       "recall      0.51355      0.513550      0.513550  \n",
       "f1-score    0.51355      0.504211      0.504211  \n",
       "support     0.51355  20000.000000  20000.000000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(multi_class=\"ovr\", random_state=0)\n",
    "svm.fit(tf_x_train,Y_train)\n",
    "y_test_predicted = svm.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.601399</td>\n",
       "      <td>0.428303</td>\n",
       "      <td>0.442865</td>\n",
       "      <td>0.495403</td>\n",
       "      <td>0.665905</td>\n",
       "      <td>0.53355</td>\n",
       "      <td>0.526775</td>\n",
       "      <td>0.526775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.399500</td>\n",
       "      <td>0.428250</td>\n",
       "      <td>0.444500</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.53355</td>\n",
       "      <td>0.533550</td>\n",
       "      <td>0.533550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.632278</td>\n",
       "      <td>0.413401</td>\n",
       "      <td>0.435435</td>\n",
       "      <td>0.468573</td>\n",
       "      <td>0.696026</td>\n",
       "      <td>0.53355</td>\n",
       "      <td>0.529142</td>\n",
       "      <td>0.529142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.53355</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1            2            3            4            5  \\\n",
       "precision     0.601399     0.428303     0.442865     0.495403     0.665905   \n",
       "recall        0.666500     0.399500     0.428250     0.444500     0.729000   \n",
       "f1-score      0.632278     0.413401     0.435435     0.468573     0.696026   \n",
       "support    4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "\n",
       "           accuracy     macro avg  weighted avg  \n",
       "precision   0.53355      0.526775      0.526775  \n",
       "recall      0.53355      0.533550      0.533550  \n",
       "f1-score    0.53355      0.529142      0.529142  \n",
       "support     0.53355  20000.000000  20000.000000  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000, solver='saga')\n",
    "lr.fit(tf_x_train,Y_train)\n",
    "y_test_predicted = lr.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Hyper-parameter tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning parameters :  {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(solver=solvers, penalty=penalty, C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "grid_result = grid_search.fit(tf_x_train, Y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best Tuning parameters : \" , grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.601263</td>\n",
       "      <td>0.428150</td>\n",
       "      <td>0.442865</td>\n",
       "      <td>0.495403</td>\n",
       "      <td>0.665905</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.526717</td>\n",
       "      <td>0.526717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.666500</td>\n",
       "      <td>0.399250</td>\n",
       "      <td>0.428250</td>\n",
       "      <td>0.444500</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.533500</td>\n",
       "      <td>0.533500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.632203</td>\n",
       "      <td>0.413195</td>\n",
       "      <td>0.435435</td>\n",
       "      <td>0.468573</td>\n",
       "      <td>0.696026</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>0.529086</td>\n",
       "      <td>0.529086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.5335</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1            2            3            4            5  \\\n",
       "precision     0.601263     0.428150     0.442865     0.495403     0.665905   \n",
       "recall        0.666500     0.399250     0.428250     0.444500     0.729000   \n",
       "f1-score      0.632203     0.413195     0.435435     0.468573     0.696026   \n",
       "support    4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "\n",
       "           accuracy     macro avg  weighted avg  \n",
       "precision    0.5335      0.526717      0.526717  \n",
       "recall       0.5335      0.533500      0.533500  \n",
       "f1-score     0.5335      0.529086      0.529086  \n",
       "support      0.5335  20000.000000  20000.000000  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = dict(solver=[\"lbfgs\"], penalty=[\"l2\"], C=[1.0])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "grid_result = grid_search.fit(tf_x_train, Y_train)\n",
    "y_test_pred = grid_search.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_pred, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.592847</td>\n",
       "      <td>0.384177</td>\n",
       "      <td>0.411308</td>\n",
       "      <td>0.458140</td>\n",
       "      <td>0.657394</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.500773</td>\n",
       "      <td>0.500773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.387250</td>\n",
       "      <td>0.423750</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.673500</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.501900</td>\n",
       "      <td>0.501900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.598862</td>\n",
       "      <td>0.385707</td>\n",
       "      <td>0.417436</td>\n",
       "      <td>0.438242</td>\n",
       "      <td>0.665349</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.501119</td>\n",
       "      <td>0.501119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1            2            3            4            5  \\\n",
       "precision     0.592847     0.384177     0.411308     0.458140     0.657394   \n",
       "recall        0.605000     0.387250     0.423750     0.420000     0.673500   \n",
       "f1-score      0.598862     0.385707     0.417436     0.438242     0.665349   \n",
       "support    4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "\n",
       "           accuracy     macro avg  weighted avg  \n",
       "precision    0.5019      0.500773      0.500773  \n",
       "recall       0.5019      0.501900      0.501900  \n",
       "f1-score     0.5019      0.501119      0.501119  \n",
       "support      0.5019  20000.000000  20000.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(tf_x_train,Y_train)\n",
    "y_test_predicted = nb.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Hyper-parameter tuning for MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 12 candidates, totalling 180 fits\n",
      "Best Tuning parameters :  {'alpha': 1.3, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameter tuning for MultinomialNB\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=999)\n",
    "grid_params = {\n",
    "    'alpha': np.linspace(0.5, 1.5, 6),\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "mul_nom_NB = GridSearchCV(estimator=MultinomialNB(),\n",
    "                          param_grid=grid_params,\n",
    "                          cv=cv_method,\n",
    "                          verbose=1,\n",
    "                          scoring='accuracy')\n",
    "mul_nom_NB.fit(tf_x_train, Y_train)\n",
    "print(\"Best Tuning parameters : \", mul_nom_NB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 1 candidates, totalling 15 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.599248</td>\n",
       "      <td>0.386182</td>\n",
       "      <td>0.412117</td>\n",
       "      <td>0.460335</td>\n",
       "      <td>0.661254</td>\n",
       "      <td>0.5029</td>\n",
       "      <td>0.503827</td>\n",
       "      <td>0.503827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.597750</td>\n",
       "      <td>0.398250</td>\n",
       "      <td>0.430250</td>\n",
       "      <td>0.426500</td>\n",
       "      <td>0.661750</td>\n",
       "      <td>0.5029</td>\n",
       "      <td>0.502900</td>\n",
       "      <td>0.502900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.598498</td>\n",
       "      <td>0.392123</td>\n",
       "      <td>0.420988</td>\n",
       "      <td>0.442772</td>\n",
       "      <td>0.661502</td>\n",
       "      <td>0.5029</td>\n",
       "      <td>0.503177</td>\n",
       "      <td>0.503177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>0.5029</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     1            2            3            4            5  \\\n",
       "precision     0.599248     0.386182     0.412117     0.460335     0.661254   \n",
       "recall        0.597750     0.398250     0.430250     0.426500     0.661750   \n",
       "f1-score      0.598498     0.392123     0.420988     0.442772     0.661502   \n",
       "support    4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n",
       "\n",
       "           accuracy     macro avg  weighted avg  \n",
       "precision    0.5029      0.503827      0.503827  \n",
       "recall       0.5029      0.502900      0.502900  \n",
       "f1-score     0.5029      0.503177      0.503177  \n",
       "support      0.5029  20000.000000  20000.000000  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params = { 'alpha': [1.5], 'fit_prior': [True] }\n",
    "\n",
    "mul_nom_NB = GridSearchCV(estimator=MultinomialNB(),\n",
    "                          param_grid=grid_params,\n",
    "                          cv=cv_method,\n",
    "                          verbose=1,\n",
    "                          scoring='accuracy')\n",
    "mul_nom_NB.fit(tf_x_train, Y_train)\n",
    "y_test_predicted = mul_nom_NB.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
