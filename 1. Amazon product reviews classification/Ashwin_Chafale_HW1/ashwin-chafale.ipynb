{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CSCI-544 Homework Assignment No. 1\n",
    "### Name : Ashwin Chafale\n",
    "### USC ID : 1990624801"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sentiment Analysis on Amazon reviews dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (0.0.1)\r\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (from bs4) (4.11.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (from beautifulsoup4->bs4) (2.3.1)\r\n",
      "Requirement already satisfied: contractions in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (0.1.72)\r\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (from contractions) (0.0.21)\r\n",
      "Requirement already satisfied: pyahocorasick in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (1.4.4)\r\n",
      "Requirement already satisfied: anyascii in /Users/ashwin/.conda/envs/HW1/lib/python3.10/site-packages (from textsearch>=0.0.21->contractions) (0.3.1)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ashwin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/ashwin/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/ashwin/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/ashwin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installation before running the notebook\n",
    "! pip install bs4\n",
    "! pip install contractions\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Read Data\n",
    "1. [Amazon reviews dataset](https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Jewelry_v1_00.tsv.gz)\n",
    "2. Our goal is to train sentiment analysis classifiers that can predict the rating value for a given review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"amazon_reviews_us_Jewelry_v1_00.tsv\", sep='\\t', header=0, on_bad_lines='skip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Keep Reviews and Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                         review_body star_rating\n0  so beautiful even tho clearly not high end ......           5\n1  Great product.. I got this set for my mother, ...           5\n2  Exactly as pictured and my daughter's friend l...           5\n3  Love it. Fits great. Super comfortable and nea...           5\n4  Got this as a Mother's Day gift for my Mom and...           5",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_body</th>\n      <th>star_rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>so beautiful even tho clearly not high end ......</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Great product.. I got this set for my mother, ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Exactly as pictured and my daughter's friend l...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Love it. Fits great. Super comfortable and nea...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Got this as a Mother's Day gift for my Mom and...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['review_body','star_rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Removing `Null` and missing values from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1766748, 2)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## We select 20000 reviews randomly from each rating class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['star_rating'] = df['star_rating'].astype(int)\n",
    "\n",
    "sample_size  = 20000\n",
    "# five_star =  df.loc[ df['star_rating'] == 5].sample(sample_size)\n",
    "# four_star =  df.loc[ df['star_rating'] == 4].sample(sample_size)\n",
    "# three_star =  df.loc[ df['star_rating'] == 3].sample(sample_size)\n",
    "# two_star =  df.loc[ df['star_rating'] == 2].sample(sample_size)\n",
    "# one_star =  df.loc[ df['star_rating'] == 1].sample(sample_size)\n",
    "five_star = df.loc[df['star_rating'] == 5][:sample_size]\n",
    "four_star = df.loc[df['star_rating'] == 4][:sample_size]\n",
    "three_star = df.loc[df['star_rating'] == 3][:sample_size]\n",
    "two_star = df.loc[df['star_rating'] == 2][:sample_size]\n",
    "one_star = df.loc[df['star_rating'] == 1][:sample_size]\n",
    "\n",
    "data = pd.concat([five_star, four_star, three_star, two_star, one_star], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of reviews before Data Cleaning step =  130.81458\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of reviews before Data Cleaning step = \", data['review_body'].str.len().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Converting all reviews to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# convert all reviews to lower case\n",
    "data[\"pre_processed_reviews\"] = data['review_body'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Removing the HTML and URLs from the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove HTML tags as well as URLs from reviews.\n",
    "data[\"pre_processed_reviews\"] = data[\"pre_processed_reviews\"].apply(lambda x: BeautifulSoup(x).get_text())\n",
    "data[\"pre_processed_reviews\"] = data[\"pre_processed_reviews\"].apply(lambda x: re.sub(r\"http\\S+\", \"\", x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3. Perform \"Contractions\" on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# contractions\n",
    "import contractions\n",
    "data[\"pre_processed_reviews\"] = data[\"pre_processed_reviews\"].apply(lambda x:contractions.fix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4. Remove the non-alpha characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove the non-alpha characters\n",
    "data[\"pre_processed_reviews\"] = data[\"pre_processed_reviews\"].apply(lambda x: \" \".join([re.sub(\"[^A-Za-z]+\",\"\", x) for x in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5. Remove extra spaces among the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove extra spaces among the words\n",
    "data['pre_processed_reviews'] = data['pre_processed_reviews'].apply(lambda x: re.sub(' +', ' ', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of reviews after Data Cleaning step =  126.72483\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of reviews after Data Cleaning step = \", data['pre_processed_reviews'].str.len().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of reviews before Data Pre-processing step =  126.72483\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of reviews before Data Pre-processing step = \", data['pre_processed_reviews'].str.len().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Remove stop words\n",
    "\n",
    "Note: Just for the purpose of pre-processing I have shown the stop-words removal.\n",
    "However, the stop-word removed pre-processed data is not used to train the model.\n",
    "\n",
    "Reason for not performing stop-word removing step:\n",
    "*I have noticed that after stop-words are not removed it leads to increase in average precision of all the ML models by 10%.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_copy = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# remove stop words using a NLTK package\n",
    "from nltk.corpus import stopwords\n",
    "sw_nltk = stopwords.words('english')\n",
    "sw_nltk.remove(\"not\")\n",
    "sw_nltk.remove(\"don\")\n",
    "sw_nltk.remove(\"don't\")\n",
    "sw_nltk.remove(\"aren't\")\n",
    "sw_nltk.remove(\"couldn't\")\n",
    "sw_nltk.remove(\"couldn\")\n",
    "sw_nltk.remove(\"didn\")\n",
    "sw_nltk.remove(\"didn't\")\n",
    "sw_nltk.remove(\"doesn\")\n",
    "sw_nltk.remove(\"doesn't\")\n",
    "sw_nltk.remove(\"won\")\n",
    "sw_nltk.remove(\"won't\")\n",
    "data_copy['pre_processed_reviews'] = data_copy['pre_processed_reviews'].apply(lambda x: \" \".join([x for x in x.split() if x not in sw_nltk]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Length of reviews after Data Pre-processing step =  78.67438\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Length of reviews after Data Pre-processing step = \", data_copy['pre_processed_reviews'].str.len().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Perform Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lemmatization using wordnet lemmatizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['pre_processed_reviews'] = data['pre_processed_reviews'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w) for w in nltk.word_tokenize(x)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TF-IDF Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  (80000,) (80000,) Test:  ((20000,), (20000,))\n"
     ]
    }
   ],
   "source": [
    "# Train - test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "five_star_X_train, five_star_X_test, five_star_Y_train, five_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 5][\"pre_processed_reviews\"],\n",
    "                 data[data[\"star_rating\"] == 5][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "four_star_X_train, four_star_X_test, four_star_Y_train, four_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 4][\"pre_processed_reviews\"],\n",
    "                 data[data[\"star_rating\"] == 4][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "three_star_X_train, three_star_X_test, three_star_Y_train, three_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 3][\"pre_processed_reviews\"],\n",
    "                 data[data[\"star_rating\"] == 3][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "two_star_X_train, two_star_X_test, two_star_Y_train, two_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 2][\"pre_processed_reviews\"],\n",
    "                 data[data[\"star_rating\"] == 2][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "one_star_X_train, one_star_X_test, one_star_Y_train, one_star_Y_test = \\\n",
    "train_test_split(data[data[\"star_rating\"] == 1][\"pre_processed_reviews\"],\n",
    "                 data[data[\"star_rating\"] == 1][\"star_rating\"], test_size=0.2, random_state=30)\n",
    "\n",
    "X_train = pd.concat([five_star_X_train, four_star_X_train, three_star_X_train, two_star_X_train, one_star_X_train])\n",
    "X_test = pd.concat([five_star_X_test, four_star_X_test, three_star_X_test, two_star_X_test, one_star_X_test])\n",
    "Y_train = pd.concat([five_star_Y_train, four_star_Y_train, three_star_Y_train, two_star_Y_train, one_star_Y_train])\n",
    "Y_test = pd.concat([five_star_Y_test, four_star_Y_test, three_star_Y_test, two_star_Y_test, one_star_Y_test])\n",
    "\n",
    "print(\"Train: \", X_train.shape, Y_train.shape, \"Test: \", (X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TF-IDF step\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_idf_vector =  TfidfVectorizer()\n",
    "tf_x_train = tf_idf_vector.fit_transform(X_train)\n",
    "tf_x_test = tf_idf_vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import classification_report\n",
    "perceptron = Perceptron(max_iter=1000, random_state=0)\n",
    "perceptron.fit(tf_x_train,Y_train)\n",
    "y_test_predicted = perceptron.predict(tf_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "output = pd.DataFrame.from_dict(report)\n",
    "output.to_csv(\"perceptron.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "svm = LinearSVC(multi_class=\"ovr\", random_state=0)\n",
    "svm.fit(tf_x_train,Y_train)\n",
    "y_test_predicted = svm.predict(tf_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "output = pd.DataFrame.from_dict(report)\n",
    "output.to_csv(\"svm.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. Simple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              precision   recall  f1-score\n1              0.601127  0.66650  0.632128\n2              0.428150  0.39925  0.413195\n3              0.442865  0.42825  0.435435\n4              0.495541  0.44450  0.468635\n5              0.665905  0.72900  0.696026\nweighted avg   0.526718  0.53350  0.529084",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.601127</td>\n      <td>0.66650</td>\n      <td>0.632128</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.428150</td>\n      <td>0.39925</td>\n      <td>0.413195</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.442865</td>\n      <td>0.42825</td>\n      <td>0.435435</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.495541</td>\n      <td>0.44450</td>\n      <td>0.468635</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.665905</td>\n      <td>0.72900</td>\n      <td>0.696026</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.526718</td>\n      <td>0.53350</td>\n      <td>0.529084</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter=1000, solver='saga')\n",
    "lr.fit(tf_x_train,Y_train)\n",
    "y_test_predicted = lr.predict(tf_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "                     1            2            3            4            5  \\\nprecision     0.592847     0.384177     0.411308     0.458140     0.657394   \nrecall        0.605000     0.387250     0.423750     0.420000     0.673500   \nf1-score      0.598862     0.385707     0.417436     0.438242     0.665349   \nsupport    4000.000000  4000.000000  4000.000000  4000.000000  4000.000000   \n\n           accuracy     macro avg  weighted avg  \nprecision    0.5019      0.500773      0.500773  \nrecall       0.5019      0.501900      0.501900  \nf1-score     0.5019      0.501119      0.501119  \nsupport      0.5019  20000.000000  20000.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>accuracy</th>\n      <th>macro avg</th>\n      <th>weighted avg</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>precision</th>\n      <td>0.592847</td>\n      <td>0.384177</td>\n      <td>0.411308</td>\n      <td>0.458140</td>\n      <td>0.657394</td>\n      <td>0.5019</td>\n      <td>0.500773</td>\n      <td>0.500773</td>\n    </tr>\n    <tr>\n      <th>recall</th>\n      <td>0.605000</td>\n      <td>0.387250</td>\n      <td>0.423750</td>\n      <td>0.420000</td>\n      <td>0.673500</td>\n      <td>0.5019</td>\n      <td>0.501900</td>\n      <td>0.501900</td>\n    </tr>\n    <tr>\n      <th>f1-score</th>\n      <td>0.598862</td>\n      <td>0.385707</td>\n      <td>0.417436</td>\n      <td>0.438242</td>\n      <td>0.665349</td>\n      <td>0.5019</td>\n      <td>0.501119</td>\n      <td>0.501119</td>\n    </tr>\n    <tr>\n      <th>support</th>\n      <td>4000.000000</td>\n      <td>4000.000000</td>\n      <td>4000.000000</td>\n      <td>4000.000000</td>\n      <td>4000.000000</td>\n      <td>0.5019</td>\n      <td>20000.000000</td>\n      <td>20000.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Hyper-parameter tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "# define models and parameters\n",
    "model = LogisticRegression(max_iter=10000)\n",
    "\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "\n",
    "# define grid search\n",
    "grid = dict(solver=solvers, penalty=penalty, C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "grid_result = grid_search.fit(tf_x_train, Y_train)\n",
    "\n",
    "# summarize results\n",
    "print(\"Best Tuning parameters : \" , grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid = dict(solver=[\"lbfgs\"], penalty=[\"l2\"], C=[1.0])\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy', error_score=0)\n",
    "grid_result = grid_search.fit(tf_x_train, Y_train)\n",
    "y_test_pred = grid_search.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_pred, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)[[\"1\", \"2\", \"3\", \"4\", \"5\", \"weighted avg\"]][:3].transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              precision   recall  f1-score\n1              0.592847  0.60500  0.598862\n2              0.384177  0.38725  0.385707\n3              0.411308  0.42375  0.417436\n4              0.458140  0.42000  0.438242\n5              0.657394  0.67350  0.665349\nweighted avg   0.500773  0.50190  0.501119",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>precision</th>\n      <th>recall</th>\n      <th>f1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.592847</td>\n      <td>0.60500</td>\n      <td>0.598862</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.384177</td>\n      <td>0.38725</td>\n      <td>0.385707</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.411308</td>\n      <td>0.42375</td>\n      <td>0.417436</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.458140</td>\n      <td>0.42000</td>\n      <td>0.438242</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.657394</td>\n      <td>0.67350</td>\n      <td>0.665349</td>\n    </tr>\n    <tr>\n      <th>weighted avg</th>\n      <td>0.500773</td>\n      <td>0.50190</td>\n      <td>0.501119</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(tf_x_train,Y_train)\n",
    "y_test_predicted = nb.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)[[\"1\", \"2\", \"3\", \"4\", \"5\", \"weighted avg\"]][:3].transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2. Hyper-parameter tuning for MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Hyper-parameter tuning for MultinomialNB\n",
    "cv_method = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=999)\n",
    "grid_params = {\n",
    "    'alpha': np.linspace(0.5, 1.5, 6),\n",
    "    'fit_prior': [True, False]\n",
    "}\n",
    "\n",
    "mul_nom_NB = GridSearchCV(estimator=MultinomialNB(),\n",
    "                          param_grid=grid_params,\n",
    "                          cv=cv_method,\n",
    "                          verbose=1,\n",
    "                          scoring='accuracy')\n",
    "mul_nom_NB.fit(tf_x_train, Y_train)\n",
    "print(\"Best Tuning parameters : \", mul_nom_NB.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grid_params = { 'alpha': [1.5], 'fit_prior': [True] }\n",
    "\n",
    "mul_nom_NB = GridSearchCV(estimator=MultinomialNB(),\n",
    "                          param_grid=grid_params,\n",
    "                          cv=cv_method,\n",
    "                          verbose=1,\n",
    "                          scoring='accuracy')\n",
    "mul_nom_NB.fit(tf_x_train, Y_train)\n",
    "y_test_predicted = mul_nom_NB.predict(tf_x_test)\n",
    "\n",
    "report = classification_report(Y_test, y_test_predicted, output_dict=True)\n",
    "pd.DataFrame.from_dict(report)[[\"1\", \"2\", \"3\", \"4\", \"5\", \"weighted avg\"]][:3].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}